{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1DRr4EQ6OxLcF5kBHm_nPmpYtix-GeEwF",
      "authorship_tag": "ABX9TyM528BKsfIKXbx+MdRxVhz7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mritunjay-07/102003030_Sampling_Assignment/blob/main/102003030_Sampling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **LOADING THE DATASET AND IMPORTING OF LIBRARIES**"
      ],
      "metadata": {
        "id": "BcR2jrdu1c29"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JIXQIaJMqP9p"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "data = pd.read_csv('/content/drive/MyDrive/All csv/Creditcard_data.csv')\n",
        "# print(data.head())\n",
        "x=data.iloc[:,0:30]\n",
        "y=data.iloc[:,30]\n",
        "\n",
        "# print(x.head())\n",
        "# print(y)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **BALANCING THE DATASET**"
      ],
      "metadata": {
        "id": "pwoSF-v91mHR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting imbalanced dataset to balanced dataset-->\n",
        "\n",
        "# Rejecting Random Under Sampling because it is causing loss of \n",
        "# information \n",
        "# from imblearn.under_sampling import RandomUnderSampler\n",
        "# rus = RandomUnderSampler(random_state=45, replacement=True)\n",
        "# x_rus, y_rus = rus.fit_resample(x, y)\n",
        "from collections import Counter\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import random\n",
        "\n",
        "smote = SMOTE()\n",
        "x_smote, y_smote = smote.fit_resample(x, y)\n",
        "\n",
        "# print('original dataset shape:', Counter(y))\n",
        "# print('Resample dataset shape', Counter(y_smote))\n"
      ],
      "metadata": {
        "id": "rPEQxUJ5rWSh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_smote['Class']=y_smote\n",
        "# print(x_smote.head())"
      ],
      "metadata": {
        "id": "ptl8b7Yv3XeU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **CREATING FIVE SAMPLES USING DIFFERENT SAMPLING TECHNIQUES**"
      ],
      "metadata": {
        "id": "MiB8foyP0gEs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample 1 using Stratified Sampling-->\n",
        "Z=1.96\n",
        "p=0.5\n",
        "E=0.10\n",
        "S=2\n",
        "n2=round((Z*Z*p*(1-p))/(E/S)**2)\n",
        "# print(n2)\n",
        "n2=int(n2/2)\n",
        "sample1 = x_smote.groupby('Class', group_keys=False).apply(lambda x: x.sample(n2))"
      ],
      "metadata": {
        "id": "9tK0sx5jmm0Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample 2 using Systematic Sampling-->\n",
        "# n = len(x_smote)\n",
        "# k = n//n1 \n",
        "# start = np.random.randint(k)\n",
        "# indices = np.arange(start, n, k)\n",
        "# x_smote[indices[:n1]]\n",
        "s=int(1526/96)\n",
        "indexes = np.arange(0, len(x_smote), step=s)\n",
        "sample2 = x_smote.iloc[indexes]\n",
        "# print(sample2)"
      ],
      "metadata": {
        "id": "EF6NVmprnY61"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample 3 using Convenience Sampling-->\n",
        "sorted_x_smote = x_smote.sort_values(['Amount', 'Time'],\n",
        "              ascending = [True, True])\n",
        "sample_size = 100\n",
        "sample = sorted_x_smote.iloc[:,25:sample_size]\n",
        "sample3=sample.iloc[:,1:]\n",
        "# print(sample3)"
      ],
      "metadata": {
        "id": "k1bRMTgd8YXq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample 4 using Cluster Sampling-->\n",
        "Z=1.96\n",
        "p=0.5\n",
        "E=0.10\n",
        "C=2\n",
        "n4=round((Z*Z*p*(1-p))/(E/C)**2)\n",
        "# print(n4)\n",
        "def Sample_Creation(data_to_work_on, data_in_each_cluster, cluster_selection):\n",
        "    N = len(data_to_work_on)\n",
        "    K = int(N/data_in_each_cluster)\n",
        "    data = None\n",
        "    for k in range(K):\n",
        "        sample_k = data_to_work_on.sample(data_in_each_cluster)\n",
        "        sample_k[\"cluster\"] = np.repeat(k,len(sample_k))\n",
        "        data_to_work_on = data_to_work_on.drop(index = sample_k.index)\n",
        "        data = pd.concat([data,sample_k],axis = 0)\n",
        "\n",
        "    random_chosen_clusters = np.random.randint(0,K,size = cluster_selection)\n",
        "    samples = data[data.cluster.isin(random_chosen_clusters)]\n",
        "    return(samples)\n",
        "\n",
        "sample4 = Sample_Creation(data_to_work_on = x_smote, data_in_each_cluster = 192, cluster_selection = C) \n",
        "sample4 = sample4.iloc[:,1:31]\n",
        "# print(sample4)"
      ],
      "metadata": {
        "id": "crT6U4G2hJV9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample 5 using Simple Random Sampling-->\n",
        "Z=1.96\n",
        "p=0.5\n",
        "E=0.10\n",
        "n1=round((Z*Z*p*(1-p))/(E*E))\n",
        "# print(n1)\n",
        "sample5 = x_smote.sample(n=n1, random_state=0)\n",
        "# random_sample.head()"
      ],
      "metadata": {
        "id": "bkFP5XZ9h6A1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **APPLYING FIVE DIFFERENT MODELS ON EACH SAMPLE**"
      ],
      "metadata": {
        "id": "6kkW1ypLUd35"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neighbors import KNeighborsClassifier"
      ],
      "metadata": {
        "id": "s2Q8FfKoUrLL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "list_of_dataframes =[sample1,sample2,sample3,sample4,sample5]\n",
        "models = {'M1': LogisticRegression(), 'M2': LinearSVC(), 'M3': DecisionTreeClassifier(),\n",
        "          'M4':GaussianNB(),'M5':KNeighborsClassifier()}\n",
        "\n",
        "scaler = StandardScaler()\n",
        "df_model = pd.DataFrame(index=models.keys())\n",
        "accuracy = {}\n",
        "\n",
        "for i, df in enumerate(list_of_dataframes, start=1):\n",
        "    X = df.iloc[:, :-1]\n",
        "    y = df.iloc[:, -1]\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=0)\n",
        "\n",
        "    X_train = scaler.fit_transform(X_train)\n",
        "    X_test = scaler.transform(X_test)\n",
        "    for keys in models.keys():\n",
        "        models[keys].fit(X_train, y_train)\n",
        "        y_pred = models[keys].predict(X_test)\n",
        "\n",
        "        accuracy[keys] = round(sklearn.metrics.accuracy_score(y_test, y_pred),2)\n",
        "    df_model['Sample'+str(i)] = accuracy.values()"
      ],
      "metadata": {
        "id": "-agTi6nPe7-b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **ACCURACY TABLE**"
      ],
      "metadata": {
        "id": "za1rc9LPqgjY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_model)"
      ],
      "metadata": {
        "id": "gvtOk7dwXRuU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f083ed8-f663-4017-c2b5-2e6226fcb5cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Sample1  Sample2  Sample3  Sample4  Sample5\n",
            "M1     0.95     0.86     0.66     0.90     0.90\n",
            "M2     0.92     0.86     0.66     0.91     0.95\n",
            "M3     0.92     0.90     0.94     0.97     0.80\n",
            "M4     0.87     0.86     0.59     0.74     0.80\n",
            "M5     0.87     0.67     0.88     0.86     0.80\n"
          ]
        }
      ]
    }
  ]
}